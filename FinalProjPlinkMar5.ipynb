{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The plink command we intend to replicate\n",
    "\"\"\"\n",
    "plink --vcf ~/1_284FinalProject/ps3_gwas.vcf.gz --linear --maf 0.05 --pheno ~/1_284FinalProject/ps3_gwas.phen --out ps3_gwas --allow-no-sex\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153de760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all of the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "from io import StringIO\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3299d0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to parse the vcf file and save to a datafrae\n",
    "def parse_vcf(vcf_path):\n",
    "    \"\"\"\n",
    "    Parses the VCF file to extract SNP information, with progress indication.\n",
    "    \n",
    "    Parameters:\n",
    "    vcf_path (str): Path to the VCF file.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with SNP information, one row per SNP.\n",
    "    \"\"\"\n",
    "    # Determine if the file is compressed and choose the appropriate opener\n",
    "    if vcf_path.endswith('.gz'):\n",
    "        opener = gzip.open\n",
    "    else:\n",
    "        opener = open\n",
    "\n",
    "    # Read the file and filter out the header lines\n",
    "    with opener(vcf_path, 'rt') as f:\n",
    "        # Use tqdm to show progress. Wrapping f in tqdm() will not give the correct total line count,\n",
    "        # so we use it to display progress without total count, or preprocess for total line count if needed.\n",
    "        lines = [l for l in tqdm(f, desc=\"Reading VCF\")]\n",
    "        data_lines = [l for l in lines if not l.startswith('##')]\n",
    "    \n",
    "    # Create a DataFrame from the filtered lines\n",
    "    vcf_df = pd.read_csv(StringIO(''.join(data_lines)), delimiter='\\t', dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str, 'QUAL': str, 'FILTER': str, 'INFO': str})\n",
    "    vcf_df.rename(columns={'#CHROM': 'CHROM'}, inplace=True)\n",
    "    return vcf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad083e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Parsing the vcf file ps3_gwas.vcf.gz\n",
    "\"\"\"\n",
    "Note: this function can take quite a while to run,\n",
    "and can be skipped for now if following dataframes are imported\n",
    "\"\"\"\n",
    "\n",
    "vcfdf = parse_vcf(\"ps3_gwas.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving vcfdf as csv\n",
    "#vcfdf.to_csv(\"vcfdfout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba48e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns from vcfdf\n",
    "columns = [\n",
    "    'CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'NA06984', 'NA06989', 'NA12878', 'NA18489',\n",
    "    'NA18504', 'NA18511', 'NA18516', 'NA18523', 'NA18908', 'NA18910', 'NA18915', 'NA18934', 'NA11832', 'NA11894', 'NA11919',\n",
    "    'NA11933', 'NA11995', 'NA12006', 'NA12044', 'NA12234', 'NA12272', 'NA12342', 'NA12347', 'NA12400', 'NA12760', 'NA11829',\n",
    "    'NA12777', 'NA11831', 'NA12828', 'NA11843', 'NA12830', 'NA11881', 'NA12842', 'NA11893', 'NA12873', 'NA11918', 'NA11920',\n",
    "    'NA11932', 'NA11994', 'NA12005', 'NA12889', 'NA18488', 'NA19095', 'NA18508', 'NA18510', 'NA18522', 'NA18864', 'NA18871',\n",
    "    'NA18876', 'NA12776', 'NA12815', 'NA12827', 'NA12872', 'NA12043', 'NA12144', 'NA12156', 'NA19153', 'NA19160', 'NA12283',\n",
    "    'NA19172', 'NA12341', 'NA19184', 'NA07037', 'NA19189', 'NA07051', 'NA07056', 'NA07347', 'NA19204', 'NA19209', 'NA18856',\n",
    "    'NA18868', 'NA18870', 'NA19099', 'NA19222', 'NA19239', 'NA19223', 'NA19235', 'NA19247', 'NA18907', 'NA18933', 'NA19108',\n",
    "    'NA19141', 'NA19146', 'NA19152', 'NA19171', 'NA19190', 'NA19210', 'NA19102', 'NA19107', 'NA19114', 'NA19119', 'NA19121',\n",
    "    'NA19138', 'NA12273', 'NA12348', 'NA12413', 'NA12716', 'NA12761', 'NA12778', 'NA12812', 'NA12829', 'NA12843', 'NA12155',\n",
    "    'NA12874', 'NA12249', 'NA12275', 'NA12282', 'NA12287', 'NA06985', 'NA12340', 'NA12383', 'NA12489', 'NA10851', 'NA11830',\n",
    "    'NA10847', 'NA11892', 'NA11931', 'NA11840', 'NA12004', 'NA12045', 'NA06994', 'NA07000', 'NA07048', 'NA18853', 'NA18916',\n",
    "    'NA18923', 'NA19096', 'NA19093', 'NA18505', 'NA19098', 'NA18517', 'NA12890', 'NA18499', 'NA18502', 'NA18507', 'NA18519',\n",
    "    'NA19116', 'NA19130', 'NA19147', 'NA19159', 'NA18858', 'NA18865', 'NA18877', 'NA12718', 'NA18909', 'NA12749', 'NA12751',\n",
    "    'NA19248', 'NA12763', 'NA12775', 'NA12814', 'NA18879', 'NA18881', 'NA19185', 'NA19197', 'NA19113', 'NA19200', 'NA19118',\n",
    "    'NA19236', 'NA19137', 'NA19144', 'NA19149', 'NA19175', 'NA19207', 'NA19214', 'NA18867', 'NA18874', 'NA19238', 'NA19257',\n",
    "    'NA07357', 'NA06986', 'NA18486', 'NA18498', 'NA18501', 'NA18520', 'NA19092', 'NA12154', 'NA12286', 'NA12399', 'NA12414',\n",
    "    'NA12546', 'NA12717', 'NA12748', 'NA12750', 'NA12762', 'NA12813', 'NA18912', 'NA18917', 'NA18924', 'NA11930', 'NA11992',\n",
    "    'NA12003','NA12046','NA12058','NA18861','NA18873','NA18878','NA19256','NA19198','NA19201','NA19206','NA19213','NA19225',\n",
    " 'NA19117','NA19129','NA19131','NA19143']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb536f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse genotypes and calculate allele counts\n",
    "def allele_counts(row):\n",
    "    alleles = row[9:].str.extractall(r'(\\d)')[0]  # Extracting alleles from genotypes, assuming genotype data starts from the 10th column\n",
    "    allele_counts = alleles.value_counts()\n",
    "    return allele_counts\n",
    "\n",
    "# Calculate allele counts for each SNP\n",
    "df_allele_counts = vcfdf.apply(allele_counts, axis=1)\n",
    "\n",
    "# Calculate MAF for each SNP\n",
    "total_alleles = 2 * (len(vcfdf.columns) - 9)  # Total alleles = 2 * number of samples, assuming genotype data starts from the 10th column\n",
    "vcfdf['MAF'] = df_allele_counts.apply(lambda x: x.min() / total_alleles if not x.empty else np.nan, axis=1)\n",
    "\n",
    "# Filter SNPs with MAF < 0.05\n",
    "filtered_df = vcfdf[vcfdf['MAF'] >= 0.05]\n",
    "\n",
    "#Save filtered_df to csv\n",
    "#filtered_df.to_csv(\"filtered_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df = pd.read_csv(\"filtered_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the first column from the DataFrame\n",
    "filtered_df = filtered_df.drop(columns=[filtered_df.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns that arent SNPs\n",
    "filtered_df = filtered_df.drop(['CHROM','POS', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac39aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in phenotype information from ps3_gwas.phen\n",
    "phenotype_df = pd.read_csv('ps3_gwas.phen', sep='\\t', header=None, names=['SampleID', 'PhenotypeValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5763fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposing filtered_df to have Sample IDs as the rows\n",
    "genotype_transposed = filtered_df.set_index('ID').transpose()\n",
    "\n",
    "#Merging the transposed genotype dataframe with the phenotype dataframe on SampleID\n",
    "merged_df = genotype_transposed.merge(phenotype_df, left_index=True, right_on='SampleID')\n",
    "\n",
    "# Setting index to 'SampleID'\n",
    "merged_df.set_index('SampleID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There were some columns from the parse_vcf function that should not have been included\n",
    "#(they did not represent SNPs), so we drop them\n",
    "rs_columns = merged_df.columns[merged_df.columns.str.startswith('rs')]\n",
    "\n",
    "# Drop columns that do not start with 'rs'\n",
    "merged_df = merged_df[rs_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop duplicate columns, keeping the first\n",
    "def drop_duplicate_columns(df):\n",
    "    return df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "#Dropping duplicate columns\n",
    "merged_df = drop_duplicate_columns(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: this function can take quite a while to run,\n",
    "and can be skipped for now if following dataframes are imported\n",
    "\"\"\"\n",
    "#Batching the dataframe into 4 sections to ensure RAM is not exceeded\n",
    "\n",
    "#Making sure all columns are strings\n",
    "merged_df = merged_df.astype(str)\n",
    "\n",
    "# Calculating the quarter point\n",
    "quarter_point = len(merged_df.columns) // 4\n",
    "\n",
    "# List to store processed columns\n",
    "processed_columns_first_quarter = []\n",
    "\n",
    "# Processing the first quarter of the columns\n",
    "for column in tqdm(merged_df.columns[:quarter_point], desc=\"Processing First Quarter\"):\n",
    "    # Split, convert to integers, and sum\n",
    "    processed_column = merged_df[column].str.split('|', expand=True).astype(int).sum(axis=1)\n",
    "    processed_columns_first_quarter.append(processed_column)\n",
    "\n",
    "#Save as df\n",
    "numeric_df_first_quarter = pd.concat(processed_columns_first_quarter, axis=1)\n",
    "numeric_df_first_quarter.columns = merged_df.columns[:quarter_point]\n",
    "\n",
    "#Create a copy to defragment\n",
    "numeric_df_first_quarter = numeric_df_first_quarter.copy()\n",
    "numeric_df_first_quarter.to_csv(\"numeric_df_first_quarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: this function can take quite a while to run,\n",
    "and can be skipped for now if following dataframes are imported\n",
    "\"\"\"\n",
    "\n",
    "# List to store processed columns\n",
    "processed_columns_second_quarter = []\n",
    "\n",
    "# Calculating the midpoint, avoiding 'PhenotypeValue' if it's the last column\n",
    "midpoint = len(merged_df.columns) // 2\n",
    "if 'PhenotypeValue' in merged_df.columns[-1]:\n",
    "    midpoint = (len(merged_df.columns) - 1) // 2\n",
    "\n",
    "# Processing the second quarter of the columns (from quarter_point to midpoint)\n",
    "for column in tqdm(merged_df.columns[quarter_point:midpoint], desc=\"Processing Second Quarter\"):\n",
    "    # Split, convert to integers, and sum\n",
    "    processed_column = merged_df[column].str.split('|', expand=True).astype(int).sum(axis=1)\n",
    "    processed_columns_second_quarter.append(processed_column)\n",
    "\n",
    "# Concatenate into a new dataframe for the second quarter\n",
    "numeric_df_second_quarter = pd.concat(processed_columns_second_quarter, axis=1)\n",
    "numeric_df_second_quarter.columns = merged_df.columns[quarter_point:midpoint]\n",
    "\n",
    "numeric_df_second_quarter = numeric_df_second_quarter.copy()\n",
    "numeric_df_second_quarter.to_csv(\"numeric_df_second_quarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: this function can take quite a while to run,\n",
    "and can be skipped for now if following dataframes are imported\n",
    "\"\"\"\n",
    "\n",
    "# List to store processed columns for the 3rd quarter\n",
    "processed_columns_third_quarter = []\n",
    "\n",
    "# Processing the 3rd quarter of the columns\n",
    "for column in tqdm(merged_df.columns[quarter_point*2:quarter_point*3], desc=\"Processing Third Quarter\"):\n",
    "    # Split, convert to integers, and sum\n",
    "    processed_column = merged_df[column].str.split('|', expand=True).astype(int).sum(axis=1)\n",
    "    processed_columns_third_quarter.append(processed_column)\n",
    "\n",
    "# Save as df\n",
    "numeric_df_third_quarter = pd.concat(processed_columns_third_quarter, axis=1)\n",
    "numeric_df_third_quarter.columns = merged_df.columns[quarter_point*2:quarter_point*3]\n",
    "\n",
    "# Create a copy to defragment\n",
    "numeric_df_third_quarter = numeric_df_third_quarter.copy()\n",
    "numeric_df_third_quarter.to_csv(\"numeric_df_third_quarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: this function can take quite a while to run,\n",
    "and can be skipped for now if following dataframes are imported\n",
    "\"\"\"\n",
    "\n",
    "# List to store processed columns for the 4th quarter\n",
    "processed_columns_fourth_quarter = []\n",
    "\n",
    "# Processing the 4th quarter of the columns\n",
    "for column in tqdm(merged_df.columns[quarter_point*3:], desc=\"Processing Fourth Quarter\"):\n",
    "    # Split, convert to integers, and sum\n",
    "    processed_column = merged_df[column].str.split('|', expand=True).astype(int).sum(axis=1)\n",
    "    processed_columns_fourth_quarter.append(processed_column)\n",
    "\n",
    "# Save as df\n",
    "numeric_df_fourth_quarter = pd.concat(processed_columns_fourth_quarter, axis=1)\n",
    "numeric_df_fourth_quarter.columns = merged_df.columns[quarter_point*3:]\n",
    "\n",
    "# Create a copy to defragment\n",
    "numeric_df_fourth_quarter = numeric_df_fourth_quarter.copy()\n",
    "numeric_df_fourth_quarter.to_csv(\"numeric_df_fourth_quarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: reading in the csvs can take quite a while to run,\n",
    "and can be skipped for now if the final dataframes are imported\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_csv(\"numeric_df_first_quarter.csv\")\n",
    "df2 = pd.read_csv(\"numeric_df_second_quarter.csv\")\n",
    "df3 = pd.read_csv(\"numeric_second_half_part1_df.csv\")\n",
    "df4 = pd.read_csv(\"numeric_second_half_part2_df.csv\")\n",
    "phenotype_df = pd.read_csv('ps3_gwas.phen', sep='\\t', header=None, names=['SampleID', 'PhenotypeValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e04c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the dataframes\n",
    "concatenated_df = pd.concat([df1, df2], axis=1)\n",
    "concatenated_df_final = pd.concat([concatenated_df, df3, df4], axis=1)\n",
    "\n",
    "#Saving concatenated_df_final as df\n",
    "#concatenated_df_final.to_csv(\"concatenated_df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdc7c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157/1604122887.py:1: DtypeWarning: Columns (840663) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  newdf = pd.read_csv(\"concatenated_df_final.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Reading in concatenated_df_final to avoid above functions if possible\n",
    "#newdf = pd.read_csv(\"concatenated_df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fb9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last column of newdf, as the phenotypes can be displayed incorrectly\n",
    "last_column = newdf.columns[-1]\n",
    "newdf = newdf.drop(last_column, axis=1)\n",
    "newdf = drop_duplicate_columns(newdf)\n",
    "\n",
    "#Merging the SNP data with the phenotypes\n",
    "newdf = newdf.merge(phenotype_df, on='SampleID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb76fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving new_df to csv\n",
    "#newdf.to_csv(\"concat_w_phen.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee045df",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35a31651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8567,\n",
       "    Unnamed: 0 SampleID  rs11252127  rs7909677  rs11591988  rs12768206  \\\n",
       " 0           0  NA06984           0          0           0           1   \n",
       " 1           1  NA06989           1          1           0           1   \n",
       " 2           2  NA12878           0          0           0           1   \n",
       " 3           3  NA18489           0          0           0           1   \n",
       " 4           4  NA18504           0          0           0           0   \n",
       " \n",
       "    rs10904561  rs7917054  rs7906287  rs9419557  ...  rs2739260  rs2229949  \\\n",
       " 0           0          1          1          0  ...          2          2   \n",
       " 1           1          1          2          0  ...          1          2   \n",
       " 2           0          1          1          0  ...          1          2   \n",
       " 3           0          1          1          0  ...          0          1   \n",
       " 4           0          0          0          0  ...          0          0   \n",
       " \n",
       "    rs3750508  rs3750510  rs9777369  rs11137376  rs17583562  rs11137379  \\\n",
       " 0          0          2          0           0           0           0   \n",
       " 1          1          2          0           0           1           1   \n",
       " 2          1          2          0           0           0           0   \n",
       " 3          0          2          1           1           0           0   \n",
       " 4          0          2          2           0           0           0   \n",
       " \n",
       "    rs9314655  PhenotypeValue  \n",
       " 0          0       -1.893857  \n",
       " 1          0        2.467882  \n",
       " 2          0       -1.565316  \n",
       " 3          1       -0.219490  \n",
       " 4          2       -0.260466  \n",
       " \n",
       " [5 rows x 832097 columns])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying and dropping columns with no variation (excluding 'SampleID' and 'PhenotypeValue')\n",
    "snp_columns = [col for col in newdf.columns if col not in ['SampleID', 'PhenotypeValue']]\n",
    "columns_to_drop = [col for col in snp_columns if newdf[col].nunique() <= 1]\n",
    "newdf_cleaned = newdf.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab800a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832093/832093 [27:28<00:00, 504.66it/s]  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note: this function can take quite a while to run,\n",
    "and can be skipped for now if final dataframes are imported\n",
    "\"\"\"\n",
    "\n",
    "#Performing linear regression\n",
    "results_summary = []\n",
    "\n",
    "for snp in tqdm(newdf_cleaned.columns[3:-1]):  # Adjust the slice as necessary to skip non-SNP columns\n",
    "    # Ensure there's variation in SNP data\n",
    "    if newdf_cleaned[snp].nunique() > 1:\n",
    "        X = sm.add_constant(newdf_cleaned[snp])  # SNP data as independent variable\n",
    "        y = newdf_cleaned['PhenotypeValue']  # Phenotype as dependent variable\n",
    "\n",
    "        # Fit the model\n",
    "        model = sm.OLS(y, X, missing='drop')  # 'missing='drop'' to handle missing values\n",
    "        result = model.fit()\n",
    "\n",
    "        if result.pvalues.shape[0] > 1:  # Check if SNP coefficient exists\n",
    "            summary = {\n",
    "                'SNP': snp,\n",
    "                'p-value': result.pvalues[1],  # p-value for SNP coefficient\n",
    "                'beta': result.params[1]  # Beta coefficient for SNP\n",
    "            }\n",
    "            results_summary.append(summary)\n",
    "        else:\n",
    "            print(f\"Model fitting issue with SNP {snp}. Likely due to constant SNP values after dropping missing data.\")\n",
    "    else:\n",
    "        print(f\"No variation in SNP {snp}. Skipping.\")\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a340e441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>p-value</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rs7909677</td>\n",
       "      <td>0.363471</td>\n",
       "      <td>0.191564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs11591988</td>\n",
       "      <td>0.504264</td>\n",
       "      <td>-0.146990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs12768206</td>\n",
       "      <td>0.547052</td>\n",
       "      <td>0.057168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs10904561</td>\n",
       "      <td>0.142948</td>\n",
       "      <td>-0.178488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs7917054</td>\n",
       "      <td>0.547052</td>\n",
       "      <td>0.057168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832088</th>\n",
       "      <td>rs9777369</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.505054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832089</th>\n",
       "      <td>rs11137376</td>\n",
       "      <td>0.034320</td>\n",
       "      <td>0.361115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832090</th>\n",
       "      <td>rs17583562</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.712181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832091</th>\n",
       "      <td>rs11137379</td>\n",
       "      <td>0.319168</td>\n",
       "      <td>-0.139623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832092</th>\n",
       "      <td>rs9314655</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.314990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SNP   p-value      beta\n",
       "0        rs7909677  0.363471  0.191564\n",
       "1       rs11591988  0.504264 -0.146990\n",
       "2       rs12768206  0.547052  0.057168\n",
       "3       rs10904561  0.142948 -0.178488\n",
       "4        rs7917054  0.547052  0.057168\n",
       "...            ...       ...       ...\n",
       "832088   rs9777369  0.000822  0.505054\n",
       "832089  rs11137376  0.034320  0.361115\n",
       "832090  rs17583562  0.001052 -0.712181\n",
       "832091  rs11137379  0.319168 -0.139623\n",
       "832092   rs9314655  0.000044  0.314990\n",
       "\n",
       "[832093 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e458d005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>p-value</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>728239</th>\n",
       "      <td>rs1319484</td>\n",
       "      <td>9.999937e-01</td>\n",
       "      <td>9.697146e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660203</th>\n",
       "      <td>rs3131012</td>\n",
       "      <td>9.999903e-01</td>\n",
       "      <td>1.178195e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660201</th>\n",
       "      <td>rs2240063</td>\n",
       "      <td>9.999903e-01</td>\n",
       "      <td>1.178195e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660200</th>\n",
       "      <td>rs2240064</td>\n",
       "      <td>9.999903e-01</td>\n",
       "      <td>1.178195e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797823</th>\n",
       "      <td>rs7041298</td>\n",
       "      <td>9.999902e-01</td>\n",
       "      <td>1.605079e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830288</th>\n",
       "      <td>rs507666</td>\n",
       "      <td>5.675715e-13</td>\n",
       "      <td>-9.908198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830286</th>\n",
       "      <td>rs2519093</td>\n",
       "      <td>5.675715e-13</td>\n",
       "      <td>-9.908198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300402</th>\n",
       "      <td>rs1531517</td>\n",
       "      <td>2.327750e-15</td>\n",
       "      <td>1.000888e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300406</th>\n",
       "      <td>rs4803750</td>\n",
       "      <td>6.102444e-29</td>\n",
       "      <td>1.898317e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300403</th>\n",
       "      <td>rs62117204</td>\n",
       "      <td>2.121923e-32</td>\n",
       "      <td>2.104528e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SNP       p-value          beta\n",
       "728239   rs1319484  9.999937e-01  9.697146e-07\n",
       "660203   rs3131012  9.999903e-01  1.178195e-06\n",
       "660201   rs2240063  9.999903e-01  1.178195e-06\n",
       "660200   rs2240064  9.999903e-01  1.178195e-06\n",
       "797823   rs7041298  9.999902e-01  1.605079e-06\n",
       "...            ...           ...           ...\n",
       "830288    rs507666  5.675715e-13 -9.908198e-01\n",
       "830286   rs2519093  5.675715e-13 -9.908198e-01\n",
       "300402   rs1531517  2.327750e-15  1.000888e+00\n",
       "300406   rs4803750  6.102444e-29  1.898317e+00\n",
       "300403  rs62117204  2.121923e-32  2.104528e+00\n",
       "\n",
       "[832093 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_sorted = results_df.sort_values(by='p-value', ascending=False)\n",
    "\n",
    "results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f3452cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving final linear regression results to csv\n",
    "#results_df_sorted.to_csv(\"linRegResults.csv\")\n",
    "#Reading in results_df_sorted\n",
    "results_df_sorted = pd.read_csv(\"linRegResults.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8c877",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d96f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviewing metrics of our linear regression compared to the output of Plink\n",
    "plinkres = pd.read_csv(\"ps3_gwas.assoc.linear\", delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c60804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHR</th>\n",
       "      <th>SNP</th>\n",
       "      <th>BP</th>\n",
       "      <th>A1</th>\n",
       "      <th>TEST</th>\n",
       "      <th>NMISS</th>\n",
       "      <th>BETA</th>\n",
       "      <th>STAT</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>rs11252127</td>\n",
       "      <td>98087</td>\n",
       "      <td>T</td>\n",
       "      <td>ADD</td>\n",
       "      <td>207</td>\n",
       "      <td>-0.20430</td>\n",
       "      <td>-1.6060</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>rs7909677</td>\n",
       "      <td>111955</td>\n",
       "      <td>G</td>\n",
       "      <td>ADD</td>\n",
       "      <td>207</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>0.3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rs11591988</td>\n",
       "      <td>126070</td>\n",
       "      <td>T</td>\n",
       "      <td>ADD</td>\n",
       "      <td>207</td>\n",
       "      <td>-0.14700</td>\n",
       "      <td>-0.6690</td>\n",
       "      <td>0.5043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>rs12768206</td>\n",
       "      <td>134767</td>\n",
       "      <td>A</td>\n",
       "      <td>ADD</td>\n",
       "      <td>207</td>\n",
       "      <td>-0.05717</td>\n",
       "      <td>-0.6032</td>\n",
       "      <td>0.5471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>rs10904561</td>\n",
       "      <td>135656</td>\n",
       "      <td>G</td>\n",
       "      <td>ADD</td>\n",
       "      <td>207</td>\n",
       "      <td>-0.17850</td>\n",
       "      <td>-1.4710</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CHR         SNP      BP A1 TEST  NMISS     BETA    STAT       P\n",
       "0   10  rs11252127   98087  T  ADD    207 -0.20430 -1.6060  0.1097\n",
       "1   10   rs7909677  111955  G  ADD    207  0.19160  0.9108  0.3635\n",
       "2   10  rs11591988  126070  T  ADD    207 -0.14700 -0.6690  0.5043\n",
       "3   10  rs12768206  134767  A  ADD    207 -0.05717 -0.6032  0.5471\n",
       "4   10  rs10904561  135656  G  ADD    207 -0.17850 -1.4710  0.1429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plinkres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc7e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging our linear regression results with the plink results on \"SNP\"\n",
    "linregcompare = pd.merge(results_df_sorted[['SNP', 'p-value', 'beta']], plinkres[['SNP', 'P', 'BETA']], on='SNP', suffixes=('_pred', '_true'))\n",
    "\n",
    "#Calculating differences between pred and true values\n",
    "linregcompare['p_value_diff'] = abs(linregcompare['p-value'] - linregcompare['P'])\n",
    "linregcompare['beta_diff'] = abs(linregcompare['beta'] - linregcompare['BETA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9318091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for p-values: 0.0001235241545070243\n",
      "MSE for p-values: 5.163739526631637e-05\n",
      "RMSE for p-values: 0.0071859164527787525\n",
      "MAE for beta coefficients: 0.11027235180768107\n",
      "MSE for beta coefficients: 0.059025047364823356\n",
      "RMSE for beta coefficients: 0.24295070974340321\n"
     ]
    }
   ],
   "source": [
    "# Computing MAE, MSE, and RMSE\n",
    "\n",
    "# For p-values\n",
    "mae_p_value = np.mean(linregcompare['p_value_diff'])\n",
    "mse_p_value = np.mean(linregcompare['p_value_diff']**2)\n",
    "rmse_p_value = np.sqrt(mse_p_value)\n",
    "\n",
    "# For beta coefficients\n",
    "mae_beta = np.mean(linregcompare['beta_diff'])\n",
    "mse_beta = np.mean(linregcompare['beta_diff']**2)\n",
    "rmse_beta = np.sqrt(mse_beta)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAE for p-values: {mae_p_value}\")\n",
    "print(f\"MSE for p-values: {mse_p_value}\")\n",
    "print(f\"RMSE for p-values: {rmse_p_value}\")\n",
    "\n",
    "print(f\"MAE for beta coefficients: {mae_beta}\")\n",
    "print(f\"MSE for beta coefficients: {mse_beta}\")\n",
    "print(f\"RMSE for beta coefficients: {rmse_beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7c327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
